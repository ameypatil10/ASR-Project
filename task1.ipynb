{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGrP5MvP4ADGwx/UEQfnPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameypatil10/ASR-Project/blob/master/task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAV4vQatrIQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0b1448-9d27-4bd7-e22d-3f253ce444e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q6zonFGrd2f"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/CS728_assignment2')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twoIDp5htj1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88bf07a-8d9c-4754-a2fe-b601be9a320b"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from multiprocessing import  Pool\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmkUkjJy4hHm"
      },
      "source": [
        "embed_size = 50\n",
        "max_words = 50000\n",
        "SEED = 10"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPdj3eBq4PxV"
      },
      "source": [
        "data = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4v6ALAf4gIr"
      },
      "source": [
        "data['compounds']=data['flea']+' '+data['market']\n",
        "data=data[['compounds','LEXICALIZED']]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2zy_iNAIkgM"
      },
      "source": [
        "def clean_text(x):\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    text = re.sub(pattern, '', x)\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlXhpwJfIqxX"
      },
      "source": [
        "data[\"compounds\"] = data[\"compounds\"].apply(lambda x: clean_text(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IHPKwX8KcfH"
      },
      "source": [
        "max_len=max(len(i.split(' ')) for i in data[\"compounds\"])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEjN6XRG5T86"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(data['compounds'], data['LEXICALIZED'],\n",
        "                                                    stratify=data['LEXICALIZED'], \n",
        "                                                    test_size=0.25)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDs31C_47Rbj"
      },
      "source": [
        "tokenizer = Tokenizer(max_words)\n",
        "tokenizer.fit_on_texts(list(train_x))\n",
        "train_x = tokenizer.texts_to_sequences(train_x)\n",
        "val_x = tokenizer.texts_to_sequences(val_x)\n",
        "\n",
        "train_x = np.asarray(pad_sequences(train_x, maxlen=max_len))\n",
        "val_x = np.asarray(pad_sequences(val_x, maxlen=max_len))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIghDdbL9Wzs"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train_y = to_categorical(le.fit_transform(train_y.values))\n",
        "val_y = to_categorical(le.transform(val_y.values))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpiacJ2MRLcP"
      },
      "source": [
        "no_of_classes=len(le.classes_)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv9-S0KB-CJg"
      },
      "source": [
        "def load_glove(word_index):\n",
        "    EMBEDDING_FILE = 'glove.6B.50d.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "    \n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = -0.005838499,0.48782197\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    nb_words = max_words\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: \n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            embedding_vector = embeddings_index.get(word.capitalize())\n",
        "            if embedding_vector is not None: \n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2SoZl6r-bSA",
        "outputId": "ccc5f998-f3aa-4692-be0d-6b729ce875af"
      },
      "source": [
        "embedding_matrix = load_glove(tokenizer.word_index)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOOHtWz7_5RQ"
      },
      "source": [
        "e = Embedding(max_words, embed_size, weights=[embedding_matrix], input_length=3, trainable=False)\n",
        "model = Sequential()\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(ReLu)\n",
        "model.add(Dense(no_of_classes,activation='sigmoid'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8IpwclxDYjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642b2dd6-7c32-452f-f034-b035f0aaadf6"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 3, 50)             2500000   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 37)                5587      \n",
            "=================================================================\n",
            "Total params: 2,505,587\n",
            "Trainable params: 5,587\n",
            "Non-trainable params: 2,500,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdmU_VEcGkBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d58cd40-e77e-43d3-caaa-9017d7d37199"
      },
      "source": [
        "model.fit(train_x, train_y ,validation_data = (val_x, val_y), epochs=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 3.1464 - accuracy: 0.1597 - val_loss: 2.4318 - val_accuracy: 0.3098\n",
            "Epoch 2/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 2.2270 - accuracy: 0.3704 - val_loss: 2.1752 - val_accuracy: 0.3832\n",
            "Epoch 3/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.9732 - accuracy: 0.4460 - val_loss: 2.0592 - val_accuracy: 0.4235\n",
            "Epoch 4/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.8136 - accuracy: 0.4842 - val_loss: 2.0013 - val_accuracy: 0.4390\n",
            "Epoch 5/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.7182 - accuracy: 0.5156 - val_loss: 1.9618 - val_accuracy: 0.4537\n",
            "Epoch 6/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.6780 - accuracy: 0.5200 - val_loss: 1.9442 - val_accuracy: 0.4611\n",
            "Epoch 7/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.6113 - accuracy: 0.5415 - val_loss: 1.9303 - val_accuracy: 0.4665\n",
            "Epoch 8/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.5901 - accuracy: 0.5452 - val_loss: 1.9254 - val_accuracy: 0.4706\n",
            "Epoch 9/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.5598 - accuracy: 0.5497 - val_loss: 1.9124 - val_accuracy: 0.4731\n",
            "Epoch 10/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.5426 - accuracy: 0.5540 - val_loss: 1.9169 - val_accuracy: 0.4768\n",
            "Epoch 11/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.5288 - accuracy: 0.5498 - val_loss: 1.9060 - val_accuracy: 0.4824\n",
            "Epoch 12/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.5138 - accuracy: 0.5632 - val_loss: 1.9208 - val_accuracy: 0.4783\n",
            "Epoch 13/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4905 - accuracy: 0.5675 - val_loss: 1.9073 - val_accuracy: 0.4851\n",
            "Epoch 14/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4950 - accuracy: 0.5662 - val_loss: 1.9094 - val_accuracy: 0.4839\n",
            "Epoch 15/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.5034 - accuracy: 0.5642 - val_loss: 1.9137 - val_accuracy: 0.4871\n",
            "Epoch 16/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4809 - accuracy: 0.5678 - val_loss: 1.9319 - val_accuracy: 0.4773\n",
            "Epoch 17/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4871 - accuracy: 0.5577 - val_loss: 1.9161 - val_accuracy: 0.4842\n",
            "Epoch 18/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4466 - accuracy: 0.5784 - val_loss: 1.9203 - val_accuracy: 0.4869\n",
            "Epoch 19/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4595 - accuracy: 0.5760 - val_loss: 1.9151 - val_accuracy: 0.4849\n",
            "Epoch 20/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4730 - accuracy: 0.5656 - val_loss: 1.9264 - val_accuracy: 0.4883\n",
            "Epoch 21/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4202 - accuracy: 0.5876 - val_loss: 1.9338 - val_accuracy: 0.4883\n",
            "Epoch 22/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4541 - accuracy: 0.5765 - val_loss: 1.9267 - val_accuracy: 0.4869\n",
            "Epoch 23/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4565 - accuracy: 0.5713 - val_loss: 1.9308 - val_accuracy: 0.4832\n",
            "Epoch 24/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4475 - accuracy: 0.5734 - val_loss: 1.9340 - val_accuracy: 0.4856\n",
            "Epoch 25/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4423 - accuracy: 0.5782 - val_loss: 1.9319 - val_accuracy: 0.4910\n",
            "Epoch 26/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4278 - accuracy: 0.5770 - val_loss: 1.9373 - val_accuracy: 0.4861\n",
            "Epoch 27/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4342 - accuracy: 0.5813 - val_loss: 1.9392 - val_accuracy: 0.4886\n",
            "Epoch 28/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4425 - accuracy: 0.5856 - val_loss: 1.9408 - val_accuracy: 0.4832\n",
            "Epoch 29/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4187 - accuracy: 0.5851 - val_loss: 1.9423 - val_accuracy: 0.4910\n",
            "Epoch 30/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4211 - accuracy: 0.5833 - val_loss: 1.9401 - val_accuracy: 0.4861\n",
            "Epoch 31/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4229 - accuracy: 0.5837 - val_loss: 1.9398 - val_accuracy: 0.4866\n",
            "Epoch 32/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4346 - accuracy: 0.5718 - val_loss: 1.9416 - val_accuracy: 0.4908\n",
            "Epoch 33/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4272 - accuracy: 0.5781 - val_loss: 1.9432 - val_accuracy: 0.4881\n",
            "Epoch 34/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4180 - accuracy: 0.5852 - val_loss: 1.9439 - val_accuracy: 0.4881\n",
            "Epoch 35/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4257 - accuracy: 0.5796 - val_loss: 1.9531 - val_accuracy: 0.4898\n",
            "Epoch 36/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4087 - accuracy: 0.5873 - val_loss: 1.9521 - val_accuracy: 0.4849\n",
            "Epoch 37/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4278 - accuracy: 0.5784 - val_loss: 1.9649 - val_accuracy: 0.4886\n",
            "Epoch 38/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3848 - accuracy: 0.5859 - val_loss: 1.9539 - val_accuracy: 0.4869\n",
            "Epoch 39/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4167 - accuracy: 0.5762 - val_loss: 1.9530 - val_accuracy: 0.4869\n",
            "Epoch 40/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3973 - accuracy: 0.5884 - val_loss: 1.9660 - val_accuracy: 0.4888\n",
            "Epoch 41/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4132 - accuracy: 0.5853 - val_loss: 1.9537 - val_accuracy: 0.4881\n",
            "Epoch 42/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4015 - accuracy: 0.5905 - val_loss: 1.9623 - val_accuracy: 0.4905\n",
            "Epoch 43/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4270 - accuracy: 0.5784 - val_loss: 1.9577 - val_accuracy: 0.4883\n",
            "Epoch 44/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4035 - accuracy: 0.5884 - val_loss: 1.9636 - val_accuracy: 0.4859\n",
            "Epoch 45/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4111 - accuracy: 0.5847 - val_loss: 1.9702 - val_accuracy: 0.4901\n",
            "Epoch 46/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3994 - accuracy: 0.5829 - val_loss: 1.9722 - val_accuracy: 0.4891\n",
            "Epoch 47/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3840 - accuracy: 0.5899 - val_loss: 1.9661 - val_accuracy: 0.4920\n",
            "Epoch 48/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4001 - accuracy: 0.5818 - val_loss: 1.9751 - val_accuracy: 0.4913\n",
            "Epoch 49/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4001 - accuracy: 0.5788 - val_loss: 1.9707 - val_accuracy: 0.4869\n",
            "Epoch 50/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3962 - accuracy: 0.5882 - val_loss: 1.9848 - val_accuracy: 0.4854\n",
            "Epoch 51/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3881 - accuracy: 0.5830 - val_loss: 1.9737 - val_accuracy: 0.4878\n",
            "Epoch 52/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3933 - accuracy: 0.5827 - val_loss: 1.9677 - val_accuracy: 0.4861\n",
            "Epoch 53/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3862 - accuracy: 0.5884 - val_loss: 1.9719 - val_accuracy: 0.4901\n",
            "Epoch 54/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3823 - accuracy: 0.5890 - val_loss: 1.9766 - val_accuracy: 0.4883\n",
            "Epoch 55/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3991 - accuracy: 0.5842 - val_loss: 1.9777 - val_accuracy: 0.4888\n",
            "Epoch 56/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3976 - accuracy: 0.5923 - val_loss: 1.9761 - val_accuracy: 0.4891\n",
            "Epoch 57/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3869 - accuracy: 0.5915 - val_loss: 1.9862 - val_accuracy: 0.4871\n",
            "Epoch 58/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3933 - accuracy: 0.5906 - val_loss: 1.9797 - val_accuracy: 0.4903\n",
            "Epoch 59/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3627 - accuracy: 0.5924 - val_loss: 1.9793 - val_accuracy: 0.4905\n",
            "Epoch 60/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3841 - accuracy: 0.5855 - val_loss: 1.9818 - val_accuracy: 0.4903\n",
            "Epoch 61/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3644 - accuracy: 0.5912 - val_loss: 1.9902 - val_accuracy: 0.4881\n",
            "Epoch 62/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3831 - accuracy: 0.5861 - val_loss: 1.9856 - val_accuracy: 0.4896\n",
            "Epoch 63/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4031 - accuracy: 0.5825 - val_loss: 1.9894 - val_accuracy: 0.4898\n",
            "Epoch 64/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3741 - accuracy: 0.5917 - val_loss: 1.9846 - val_accuracy: 0.4918\n",
            "Epoch 65/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3940 - accuracy: 0.5857 - val_loss: 1.9830 - val_accuracy: 0.4908\n",
            "Epoch 66/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3765 - accuracy: 0.5892 - val_loss: 1.9944 - val_accuracy: 0.4881\n",
            "Epoch 67/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3788 - accuracy: 0.5950 - val_loss: 1.9897 - val_accuracy: 0.4873\n",
            "Epoch 68/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3652 - accuracy: 0.5906 - val_loss: 1.9879 - val_accuracy: 0.4940\n",
            "Epoch 69/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3868 - accuracy: 0.5935 - val_loss: 1.9924 - val_accuracy: 0.4920\n",
            "Epoch 70/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3750 - accuracy: 0.5943 - val_loss: 1.9931 - val_accuracy: 0.4888\n",
            "Epoch 71/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3786 - accuracy: 0.5920 - val_loss: 2.0010 - val_accuracy: 0.4881\n",
            "Epoch 72/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3658 - accuracy: 0.6015 - val_loss: 1.9903 - val_accuracy: 0.4937\n",
            "Epoch 73/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.4025 - accuracy: 0.5856 - val_loss: 2.0004 - val_accuracy: 0.4910\n",
            "Epoch 74/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3909 - accuracy: 0.5875 - val_loss: 2.0050 - val_accuracy: 0.4864\n",
            "Epoch 75/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3675 - accuracy: 0.5912 - val_loss: 1.9968 - val_accuracy: 0.4908\n",
            "Epoch 76/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3866 - accuracy: 0.5873 - val_loss: 2.0014 - val_accuracy: 0.4881\n",
            "Epoch 77/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3847 - accuracy: 0.5877 - val_loss: 1.9955 - val_accuracy: 0.4903\n",
            "Epoch 78/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3998 - accuracy: 0.5870 - val_loss: 1.9985 - val_accuracy: 0.4940\n",
            "Epoch 79/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3879 - accuracy: 0.5864 - val_loss: 2.0064 - val_accuracy: 0.4915\n",
            "Epoch 80/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3806 - accuracy: 0.5876 - val_loss: 2.0073 - val_accuracy: 0.4881\n",
            "Epoch 81/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3939 - accuracy: 0.5834 - val_loss: 2.0010 - val_accuracy: 0.4876\n",
            "Epoch 82/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3680 - accuracy: 0.5972 - val_loss: 2.0001 - val_accuracy: 0.4905\n",
            "Epoch 83/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3520 - accuracy: 0.6003 - val_loss: 2.0111 - val_accuracy: 0.4871\n",
            "Epoch 84/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3911 - accuracy: 0.5899 - val_loss: 2.0037 - val_accuracy: 0.4903\n",
            "Epoch 85/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3951 - accuracy: 0.5894 - val_loss: 2.0038 - val_accuracy: 0.4905\n",
            "Epoch 86/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3847 - accuracy: 0.5840 - val_loss: 2.0069 - val_accuracy: 0.4891\n",
            "Epoch 87/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3713 - accuracy: 0.5928 - val_loss: 2.0121 - val_accuracy: 0.4873\n",
            "Epoch 88/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3757 - accuracy: 0.5903 - val_loss: 2.0048 - val_accuracy: 0.4905\n",
            "Epoch 89/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3665 - accuracy: 0.5856 - val_loss: 2.0158 - val_accuracy: 0.4883\n",
            "Epoch 90/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3584 - accuracy: 0.5974 - val_loss: 2.0181 - val_accuracy: 0.4883\n",
            "Epoch 91/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3821 - accuracy: 0.5890 - val_loss: 2.0083 - val_accuracy: 0.4915\n",
            "Epoch 92/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3604 - accuracy: 0.5959 - val_loss: 2.0114 - val_accuracy: 0.4883\n",
            "Epoch 93/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3811 - accuracy: 0.5932 - val_loss: 2.0096 - val_accuracy: 0.4905\n",
            "Epoch 94/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3594 - accuracy: 0.5975 - val_loss: 2.0197 - val_accuracy: 0.4891\n",
            "Epoch 95/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3841 - accuracy: 0.5912 - val_loss: 2.0144 - val_accuracy: 0.4928\n",
            "Epoch 96/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3681 - accuracy: 0.5898 - val_loss: 2.0188 - val_accuracy: 0.4908\n",
            "Epoch 97/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3668 - accuracy: 0.5923 - val_loss: 2.0214 - val_accuracy: 0.4935\n",
            "Epoch 98/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3794 - accuracy: 0.5929 - val_loss: 2.0143 - val_accuracy: 0.4893\n",
            "Epoch 99/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3547 - accuracy: 0.5955 - val_loss: 2.0178 - val_accuracy: 0.4903\n",
            "Epoch 100/100\n",
            "382/382 [==============================] - 1s 2ms/step - loss: 1.3715 - accuracy: 0.5950 - val_loss: 2.0176 - val_accuracy: 0.4903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e0c293350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}